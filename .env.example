# AdGuard Home Configuration
AGH_URL=http://192.168.1.2:8080
AGH_USER=admin
AGH_PASS=password

# Application Configuration
POLL_INTERVAL=10s
DB_PATH=./data/guardian.db
LOG_LEVEL=info

# For Milestone 2+ (LLM Integration)
# LLM provider: gemini (recommended - free tier), ollama (local), openai, anthropic
LLM_PROVIDER=gemini

# Gemini Configuration (get free API key at https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-flash

# Optional: Other LLM Providers
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
# OLLAMA_URL=http://localhost:11434
# OLLAMA_MODEL=llama3

# LLM Settings
LLM_TIMEOUT=30s
LLM_ENABLE=true

# LLM Batch Processing (Rate Limiting)
# These settings control how domains are batched before sending to the LLM
# Default settings are optimized for Gemini free tier (15 RPM limit)
LLM_BATCH_SIZE=20          # Number of domains to analyze per API call
LLM_BATCH_TIMEOUT=60s      # Maximum time to wait before processing a partial batch
LLM_BATCH_DELAY=60s        # Minimum delay between batch requests (prevents rate limiting)

# IMPORTANT: If you're getting rate limited frequently, try:
# - Increase LLM_BATCH_DELAY to 90s or 120s
# - Increase LLM_BATCH_SIZE to 30 or 40
# - Increase LLM_BATCH_TIMEOUT to 120s
